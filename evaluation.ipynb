{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a42d9e64",
   "metadata": {},
   "source": [
    "# Evaluation Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63330167",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ef015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas seaborn torch torchvision torchsummary torchtext pytorch_lightning tensorboard matplotlib tqdm datetime time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735bb817",
   "metadata": {},
   "source": [
    "## Download Data\n",
    "\n",
    "either provide a download link here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c51c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2e4cfb5",
   "metadata": {},
   "source": [
    "## Your Plots and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3149902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloader import LandCoverData\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as clr\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from torchvision.models.segmentation import deeplabv3_resnet101\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from src.model import UNet\n",
    "from src.dataloader import LandCoverData, transformsNorm\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a0608",
   "metadata": {},
   "source": [
    "# 1. Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339a4c56",
   "metadata": {},
   "source": [
    "## If you want to see the result of our data augmentation run the following cells,\n",
    "## Otherwise jump to the part 2.Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12adc4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "YOU NEED TO DOWNLOAD THE DATA IN THE ipeo_data/ folder.\n",
    "SEE README OF THE REPO GITHUB.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31153c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"data/ipeo_data/\"\n",
    "path_augmented_rgb =\"data/ipeo_data/augmented_data_rgb/\"\n",
    "path_augmented_label =\"data/ipeo_data/augmented_data_label/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964d576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = LandCoverData(path, transforms=None, split=\"train\", ignore_last_number=11, use_augmented=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water and wetlands is less represented, -> index=4\n",
    "for index_augmentation in range(1, 6):\n",
    "    toPIL = T.ToPILImage()\n",
    "\n",
    "    tt_class=np.zeros(len(dataset2.LABEL_CLASSES))\n",
    "    index_label=0\n",
    "    for img, label in tqdm(dataset2):\n",
    "        class_list, class_count = torch.unique(label, return_counts=True) \n",
    "        if index_augmentation in class_list:\n",
    "            #print(index_label)\n",
    "            #fig, ax = plt.subplots(1,8, figsize=(16, 20))\n",
    "            #ax[0].imshow(toPIL(img))\n",
    "            #ax[1].imshow(toPIL(label), cmap=cmap, vmin=0, vmax=len(dataset2.LABEL_CLASSES))\n",
    "            for i in range(1,4):\n",
    "                rotation_deg = i * 90 #Only performs flip\n",
    "                path = \"/\"\n",
    "                name_image = f\"{index_label}_{i}_rgb\"\n",
    "                name_label = f\"{index_label}_{i}_label\"\n",
    "\n",
    "                rotated = toPIL(img).rotate(rotation_deg,expand=0)\n",
    "                #ax[i*2].imshow(rotated)\n",
    "                rotated.save(path_augmented_rgb+name_image+\".tif\")\n",
    "                rotated = toPIL(label).rotate(rotation_deg,expand=0)\n",
    "                rotated.save(path_augmented_label+name_label+\".tif\")\n",
    "                #ax[i*2+1].imshow(rotated, cmap=cmap, vmin=0, vmax=len(dataset2.LABEL_CLASSES))\n",
    "        index_label+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da299649",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_final = LandCoverData(path, transforms=None, split=\"train\", ignore_last_number=11, use_augmented=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83aa7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_class=np.zeros(len(dataset_final.LABEL_CLASSES))\n",
    "for _, label in tqdm(dataset_final):\n",
    "    class_list, class_count = torch.unique(label, return_counts=True)  \n",
    "    for i, c in enumerate(class_list):\n",
    "        tt_class[c]+=class_count[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b2c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "labels = [k for k in dataset_final.LABEL_CLASSES.keys()]\n",
    "indexes = np.arange(len(labels))\n",
    "\n",
    "rescale = lambda indexes: (indexes - np.min(indexes)) / (np.max(indexes) - np.min(indexes))\n",
    "\n",
    "width = 0.8\n",
    "plt.barh(indexes, tt_class, color=cmap(rescale(indexes)))\n",
    "plt.yticks(indexes, labels)\n",
    "plt.xlabel('Pixels count', fontsize=16)\n",
    "plt.ylabel('Class', fontsize=16)\n",
    "plt.title('Barchart - Frequency of each class',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b29ec28",
   "metadata": {},
   "source": [
    "# 2. Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d5e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "YOU NEED TO DOWNLOAD THE MODEL IN THE checkpoints/ folder.\n",
    "SEE README OF THE REPO GITHUB.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "unet = UNet(nbClasses=8)\n",
    "\n",
    "# To use DeepLabV3 pretrained model:\n",
    "#unet = deeplabv3_resnet101(pretrained=True, progress=True)\n",
    "#unet.classifier = DeepLabHead(2048, 8)\n",
    "\n",
    "PATH_MODEL = 'checkpoints/best_model_acc_cross_entropy_Batch_32_loss.pth'\n",
    "\n",
    "unet.load_state_dict(torch.load(PATH_MODEL, map_location=torch.device('cpu')))\n",
    "\n",
    "unet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b402c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "YOU NEED TO DOWNLOAD THE TEST DATA IN THE ipeo_data/ folder.\n",
    "SEE README OF THE REPO GITHUB.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "path=\"data/ipeo_data/\"\n",
    "\n",
    "transformsData, unnormalize = transformsNorm(flag_plot=True)\n",
    "\n",
    "test_dataset = LandCoverData(path=path, \n",
    "                             transforms=transformsData,\n",
    "                             split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c153b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = clr.LinearSegmentedColormap.from_list('custom_datacolor', test_dataset.colormap_names, N=256)\n",
    "#cmap='viridis'\n",
    "#cmap=dataset.colormap\n",
    "\n",
    "# plot individual samples\n",
    "from ipywidgets import widgets\n",
    "from ipywidgets import interact\n",
    "%matplotlib inline\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "widget=widgets.BoundedIntText(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(test_dataset),\n",
    "    step=1,\n",
    "    description=f\"Index data: (max={len(test_dataset)})\",\n",
    "    disabled=False,\n",
    "    style=style\n",
    ")\n",
    "widget_cb=widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Colorbar',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "@interact(idx=widget, flag_colorbar=widget_cb)\n",
    "def plot_sample(idx=0, flag_colorbar=False):\n",
    "    roffset=1\n",
    "    if flag_colorbar:\n",
    "        roffset=1.07\n",
    "    fig, ax = plt.subplots(1,3, figsize=(12, 10), gridspec_kw={'width_ratios': [1, 1, roffset]})    \n",
    "    \n",
    "    class_mapping = {v: k for k, v in test_dataset.LABEL_CLASSES.items()}  \n",
    "    \n",
    "    x, y = test_dataset[idx]\n",
    "    x=x.unsqueeze(dim=0)\n",
    "    \n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "    # For DeepLabV3:\n",
    "    #preds = torch.argmax(softmax(unet(x)['out']),axis=1)\n",
    "    # Otherwise\n",
    "    preds = torch.argmax(softmax(unet(x)),axis=1)\n",
    "    x = unnormalize(x)\n",
    "    img = np.transpose(np.array(x[0,:,:]),(1,2,0))\n",
    "    preds = np.array(preds[0,:,:])\n",
    "    mask = np.array(y[0,:,:])\n",
    "    \n",
    "    ax[0].imshow(img)\n",
    "    ax[1].imshow(preds, cmap=cmap, vmin=0, vmax=len(test_dataset.LABEL_CLASSES))\n",
    "    pim=ax[2].imshow(mask, cmap=cmap, vmin=0, vmax=len(test_dataset.LABEL_CLASSES))\n",
    "    \n",
    "    if flag_colorbar:\n",
    "        class_list, _ = torch.unique(y[0,:,:], return_counts=True)\n",
    "        divider = make_axes_locatable(ax[2])\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "        cbar = fig.colorbar(pim, cax=cax, ax=ax.ravel().tolist())\n",
    "        if cmap==test_dataset.colormap:\n",
    "            cbar.set_ticks([i.item()+0.5 for i in class_list])\n",
    "        else:\n",
    "            cbar.set_ticks([i.item() for i in class_list])\n",
    "        cbar.set_ticklabels([class_mapping[i.item()] for i in class_list])\n",
    "\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[2].axis(\"off\")\n",
    "    ax[0].set_title(f\"Image\")\n",
    "    ax[1].set_title(f\"Prediction\")\n",
    "    ax[2].set_title(f\"Ground Truth\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed6ab1",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d374aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "\n",
    "#unet=unet.to(DEVICE)\n",
    "unet = UNet(nbClasses=8).to(DEVICE)\n",
    "unet.load_state_dict(torch.load(PATH_MODEL, map_location=torch.device(DEVICE)))\n",
    "\n",
    "y_pred = torch.zeros(0).to(DEVICE)\n",
    "y_true = torch.zeros(0).to(DEVICE)\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "# iterate over test data\n",
    "for x, labels in tqdm(test_dataset):\n",
    "    (x, labels) = (x.to(DEVICE), labels.to(DEVICE))\n",
    "    x=x.unsqueeze(dim=0)\n",
    "    \n",
    "    preds = torch.argmax(softmax(unet(x)),axis=1)\n",
    "    y_pred = torch.cat([y_pred,preds]) # Save Prediction\n",
    "        \n",
    "    #labels = labels.data.cpu().numpy()\n",
    "    y_true = torch.cat([y_true,labels]) # Save Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b98a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = MulticlassConfusionMatrix(num_classes=8, normalize='none').to(DEVICE)\n",
    "cf_matrix = metric(y_pred, y_true)\n",
    "cf_matrix_np = cf_matrix.cpu().numpy()\n",
    "\n",
    "# constant for classes\n",
    "classes = ('Grass and other', 'Wald',\n",
    "           'Bushes and sparse forest', 'Water and wetlands',\n",
    "           'Glaciers and permanent snow', 'Sparse rocks (rocks mixed with grass)',\n",
    "           'Loose rocks, scree', 'Bed rocks')\n",
    "\n",
    "plt.figure(figsize = (12,9))\n",
    "df_cm = pd.DataFrame(cf_matrix_np, index = [i for i in classes], columns = [i for i in classes])\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86700833",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_class_acc = (cf_matrix.diag()/cf_matrix.sum(1)).cpu().numpy()\n",
    "plt.figure(figsize = (12,1))\n",
    "plt.tight_layout()\n",
    "df_per_class_acc = pd.DataFrame([per_class_acc], columns = [i for i in classes])\n",
    "sn.heatmap(df_per_class_acc, annot=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a7089d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
