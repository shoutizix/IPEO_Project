{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740be313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USEFUL WHEN RUNNING ON CLUSTER\n",
    "#import sys\n",
    "#!pip install torch torchvision torchtext pytorch_lightning tensorboard matplotlib tqdm datetime time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1516afb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67d3e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eddd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim import SGD\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from src.model import UNet\n",
    "from src.dataloader import LandCoverData\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a4fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../\"\n",
    "\n",
    "train_dataset = LandCoverData(path, transforms=None, split=\"train\")\n",
    "val_dataset = LandCoverData(path, transforms=None, split=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08078119",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "# num_workers 8 default but 2 on colab\n",
    "train_dl = DataLoader(train_dataset, BATCH_SIZE, True, num_workers=2)\n",
    "val_dl = DataLoader(val_dataset, BATCH_SIZE, False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7dc93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMAGE_HEIGHT=200\n",
    "INPUT_IMAGE_WIDTH=200\n",
    "\n",
    "#DEVICE = \"cuda\"\n",
    "DEVICE = \"cpu\"\n",
    "INIT_LR = 0.001\n",
    "INIT_MOMENTUM = 0.9\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973cfaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our UNet model\n",
    "unet = UNet(nbClasses=8).to(DEVICE)\n",
    "# initialize loss function and optimizer\n",
    "lossFunc = CrossEntropyLoss()\n",
    "opt = SGD(unet.parameters(), lr=INIT_LR, momentum=INIT_MOMENTUM)\n",
    "# calculate steps per epoch for training and test set\n",
    "trainSteps = len(train_dataset) // BATCH_SIZE\n",
    "testSteps = len(val_dataset) // BATCH_SIZE\n",
    "# initialize a dictionary to store training history\n",
    "H = {\"train_loss\": [], \"test_loss\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db3fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over epochs\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()\n",
    "#for e in tqdm(range(NUM_EPOCHS)):\n",
    "for e in tqdm(range(NUM_EPOCHS)):\n",
    "    # set the model in training mode\n",
    "    unet.train()\n",
    "    # initialize the total training and validation loss\n",
    "    totalTrainLoss = 0\n",
    "    totalTestLoss = 0\n",
    "    # loop over the training set\n",
    "    for (i, (x, y)) in enumerate(train_dl):\n",
    "        # send the input to the device\n",
    "        (x, y) = (x.to(DEVICE), y.to(DEVICE))\n",
    "        # perform a forward pass and calculate the training loss\n",
    "        pred = unet(x)\n",
    "\n",
    "        y = y.to(torch.long)\n",
    "        y = y.squeeze()\n",
    "\n",
    "        loss = lossFunc(pred, y)\n",
    "        \n",
    "        # first, zero out any previously accumulated gradients, then\n",
    "        # perform backpropagation, and then update model parameters\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        # add the loss to the total training loss so far\n",
    "        totalTrainLoss += loss\n",
    "    # switch off autograd\n",
    "    with torch.no_grad():\n",
    "        # set the model in evaluation mode\n",
    "        unet.eval()\n",
    "        # loop over the validation set\n",
    "        for (x, y) in val_dl:\n",
    "            # send the input to the device\n",
    "            (x, y) = (x.to(DEVICE), y.to(DEVICE))\n",
    "            # make the predictions and calculate the validation loss\n",
    "            pred = unet(x)\n",
    "            #pred=pred.to(torch.float32)\n",
    "            y = y.to(torch.long)\n",
    "            y = y.squeeze()\n",
    "            totalTestLoss += lossFunc(pred, y)\n",
    "\n",
    "    # calculate the average training and validation loss\n",
    "    avgTrainLoss = totalTrainLoss / trainSteps\n",
    "    avgTestLoss = totalTestLoss / testSteps\n",
    "    # update our training history\n",
    "    H[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "    H[\"test_loss\"].append(avgTestLoss.cpu().detach().numpy())\n",
    "    # print the model training and validation information\n",
    "    print(\"[INFO] EPOCH: {}/{}\".format(e + 1, NUM_EPOCHS))\n",
    "    print(\"Train loss: {:.6f}, Test loss: {:.4f}\".format(\n",
    "      avgTrainLoss, avgTestLoss))\n",
    "# display the total time needed to perform the training\n",
    "endTime = time.time()\n",
    "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9867c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.datetime.now()\n",
    "date_ymd = date.date()\n",
    "date_hm = f\"{date.hour}:{date.minute}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e72473",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(H[\"test_loss\"], label=\"test_loss\")\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(f\"train_val_loss_{date_ymd}_{date_hm}.png, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef9d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(unet.state_dict(), 'model.pth')\n",
    "torch.save(unet, f\"unet_model_{date_ymd}_{date_hm}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
